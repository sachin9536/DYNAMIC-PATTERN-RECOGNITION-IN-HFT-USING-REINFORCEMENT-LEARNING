{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Market Anomaly Detection - Explainability Demo\n",
                "\n",
                "This notebook demonstrates the explainability features of our market anomaly detection system.\n",
                "We'll show how to use SHAP, LIME, attention mechanisms, and rule-based explanations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "sys.path.append('..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "\n",
                "# Import our explainability modules\n",
                "from src.explainability.interface import explain_instance, pretty_print_explanation\n",
                "from src.explainability.visualization import (\n",
                "    plot_shap_summary, plot_lime_explanation, plot_attention_heatmap,\n",
                "    create_explanation_dashboard, plot_feature_importance_comparison\n",
                ")\n",
                "from src.explainability.rule_based import MarketAnomalyRules\n",
                "\n",
                "# Import data and model utilities\n",
                "from src.data.synthetic_market_data import SyntheticMarketDataGenerator\n",
                "from src.data.preprocessing import MarketDataPreprocessor\n",
                "\n",
                "plt.style.use('seaborn-v0_8')\n",
                "sns.set_palette(\"husl\")\n",
                "\n",
                "print(\"âœ… Imports successful!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Generate Sample Data\n",
                "\n",
                "First, let's generate some synthetic market data with anomalies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate synthetic market data\n",
                "data_generator = SyntheticMarketDataGenerator()\n",
                "market_data = data_generator.generate_market_session(\n",
                "    n_samples=1000,\n",
                "    anomaly_probability=0.1,\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Generated {len(market_data)} market data points\")\n",
                "print(f\"Columns: {list(market_data.columns)}\")\n",
                "\n",
                "# Show sample data\n",
                "market_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocess the data\n",
                "preprocessor = MarketDataPreprocessor()\n",
                "processed_data = preprocessor.preprocess_data(market_data)\n",
                "\n",
                "print(f\"Processed data shape: {processed_data.shape}\")\n",
                "print(f\"Feature names: {preprocessor.feature_names}\")\n",
                "\n",
                "# Split into normal and anomalous samples\n",
                "anomaly_mask = market_data['is_anomaly'].values\n",
                "normal_samples = processed_data[~anomaly_mask]\n",
                "anomalous_samples = processed_data[anomaly_mask]\n",
                "\n",
                "print(f\"Normal samples: {len(normal_samples)}\")\n",
                "print(f\"Anomalous samples: {len(anomalous_samples)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train a Simple Model\n",
                "\n",
                "Let's train a simple model for demonstration purposes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "# Prepare training data\n",
                "X = processed_data\n",
                "y = anomaly_mask.astype(int)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "# Train model\n",
                "model = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=10,\n",
                "    random_state=42\n",
                ")\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Evaluate model\n",
                "y_pred = model.predict(X_test)\n",
                "print(\"Model Performance:\")\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "print(f\"\\nModel trained on {len(X_train)} samples\")\n",
                "print(f\"Test accuracy: {model.score(X_test, y_test):.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. SHAP Explanations\n",
                "\n",
                "Let's use SHAP to explain model predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select some test samples for explanation\n",
                "test_samples = X_test[:5]  # First 5 test samples\n",
                "feature_names = preprocessor.feature_names\n",
                "\n",
                "print(\"Running SHAP explanation...\")\n",
                "shap_explanation = explain_instance(\n",
                "    model=model,\n",
                "    observation=test_samples,\n",
                "    method='shap',\n",
                "    feature_names=feature_names,\n",
                "    nsamples=50,  # Reduced for demo speed\n",
                "    cache=False\n",
                ")\n",
                "\n",
                "print(pretty_print_explanation(shap_explanation))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize SHAP results\n",
                "if 'shap_values' in shap_explanation:\n",
                "    plt.figure(figsize=(12, 8))\n",
                "    plot_meta = plot_shap_summary(shap_explanation, figsize=(12, 8))\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"SHAP visualization metadata: {plot_meta}\")\nelse:\n",
                "    print(\"SHAP values not available for visualization\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. LIME Explanations\n",
                "\n",
                "Now let's try LIME explanations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Running LIME explanation...\")\n",
                "lime_explanation = explain_instance(\n",
                "    model=model,\n",
                "    observation=test_samples[:3],  # First 3 samples for LIME\n",
                "    method='lime',\n",
                "    feature_names=feature_names,\n",
                "    num_features=8,\n",
                "    cache=False\n",
                ")\n",
                "\n",
                "print(pretty_print_explanation(lime_explanation))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize LIME results\n",
                "if 'explanations' in lime_explanation and lime_explanation['explanations']:\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plot_meta = plot_lime_explanation(lime_explanation, instance_idx=0, figsize=(12, 6))\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"LIME visualization metadata: {plot_meta}\")\nelse:\n",
                "    print(\"LIME explanations not available for visualization\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Rule-Based Explanations\n",
                "\n",
                "Let's use our rule-based system to explain anomalies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize rule-based system\n",
                "rule_system = MarketAnomalyRules()\n",
                "\n",
                "# Show rule system summary\n",
                "rule_summary = rule_system.get_rule_summary()\n",
                "print(\"Rule System Summary:\")\n",
                "print(f\"Total rules: {rule_summary['total_rules']}\")\n",
                "print(f\"Rule types: {rule_summary['rule_types']}\")\n",
                "print(f\"Rule names: {rule_summary['rule_names']}\")\n",
                "print(f\"Thresholds: {rule_summary['thresholds']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test rule-based explanations on some samples\n",
                "print(\"Testing rule-based explanations...\")\n",
                "\n",
                "# Test on a normal sample\n",
                "normal_sample = normal_samples[0]\n",
                "normal_explanation = rule_system.explain_observation(normal_sample, feature_names)\n",
                "\n",
                "print(\"\\n--- Normal Sample ---\")\n",
                "print(f\"Anomaly score: {normal_explanation['anomaly_score']:.3f}\")\n",
                "print(f\"Triggered rules: {normal_explanation['triggered_rules']}\")\n",
                "print(f\"Explanation: {normal_explanation['explanation_text']}\")\n",
                "\n",
                "# Test on an anomalous sample\n",
                "if len(anomalous_samples) > 0:\n",
                "    anomalous_sample = anomalous_samples[0]\n",
                "    anomalous_explanation = rule_system.explain_observation(anomalous_sample, feature_names)\n",
                "    \n",
                "    print(\"\\n--- Anomalous Sample ---\")\n",
                "    print(f\"Anomaly score: {anomalous_explanation['anomaly_score']:.3f}\")\n",
                "    print(f\"Triggered rules: {anomalous_explanation['triggered_rules']}\")\n",
                "    print(f\"Explanation: {anomalous_explanation['explanation_text']}\")\nelse:\n",
                "    print(\"\\nNo anomalous samples available for testing\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run rule-based explanation through the unified interface\n",
                "print(\"Running rule-based explanation through unified interface...\")\n",
                "rule_explanation = explain_instance(\n",
                "    model=model,  # Model not used for rule-based, but required by interface\n",
                "    observation=test_samples[0],\n",
                "    method='rule',\n",
                "    feature_names=feature_names,\n",
                "    cache=False\n",
                ")\n",
                "\n",
                "print(pretty_print_explanation(rule_explanation))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Comparison Dashboard\n",
                "\n",
                "Let's create a comprehensive dashboard comparing all explanation methods."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect all explanations\n",
                "all_explanations = []\n",
                "\n",
                "if 'shap_values' in shap_explanation:\n",
                "    all_explanations.append(shap_explanation)\n",
                "\n",
                "if 'explanations' in lime_explanation:\n",
                "    all_explanations.append(lime_explanation)\n",
                "\n",
                "all_explanations.append(rule_explanation)\n",
                "\n",
                "print(f\"Creating dashboard with {len(all_explanations)} explanations...\")\n",
                "\n",
                "# Create dashboard\n",
                "dashboard_dir = \"../artifacts/explanations/demo_dashboard\"\n",
                "dashboard_data = create_explanation_dashboard(\n",
                "    all_explanations,\n",
                "    save_dir=dashboard_dir,\n",
                "    title=\"Market Anomaly Detection - Explainability Demo\"\n",
                ")\n",
                "\n",
                "print(f\"Dashboard created in {dashboard_dir}\")\n",
                "print(f\"Summary: {dashboard_data['summary']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create feature importance comparison\n",
                "if len(all_explanations) > 1:\n",
                "    plt.figure(figsize=(14, 8))\n",
                "    comparison_meta = plot_feature_importance_comparison(\n",
                "        all_explanations,\n",
                "        figsize=(14, 8)\n",
                "    )\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"Feature importance comparison: {comparison_meta}\")\nelse:\n",
                "    print(\"Not enough explanations for comparison plot\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Interactive Analysis\n",
                "\n",
                "Let's create some interactive analysis tools."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze multiple samples and compare explanations\n",
                "def analyze_sample(sample_idx):\n",
                "    \"\"\"Analyze a specific sample with all explanation methods.\"\"\"\n",
                "    sample = X_test[sample_idx:sample_idx+1]\n",
                "    true_label = y_test[sample_idx]\n",
                "    pred_label = model.predict(sample)[0]\n",
                "    pred_proba = model.predict_proba(sample)[0]\n",
                "    \n",
                "    print(f\"\\n=== Sample {sample_idx} Analysis ===\")\n",
                "    print(f\"True label: {true_label} ({'Anomaly' if true_label else 'Normal'})\")\n",
                "    print(f\"Predicted: {pred_label} ({'Anomaly' if pred_label else 'Normal'})\")\n",
                "    print(f\"Prediction confidence: {pred_proba[pred_label]:.3f}\")\n",
                "    \n",
                "    # Rule-based explanation (fastest)\n",
                "    rule_exp = explain_instance(\n",
                "        model=model,\n",
                "        observation=sample[0],\n",
                "        method='rule',\n",
                "        feature_names=feature_names,\n",
                "        cache=False\n",
                "    )\n",
                "    \n",
                "    print(\"\\n--- Rule-based Explanation ---\")\n",
                "    print(f\"Anomaly score: {rule_exp.get('anomaly_score', 0):.3f}\")\n",
                "    print(f\"Triggered rules: {len(rule_exp.get('triggered_rules', []))}\")\n",
                "    if rule_exp.get('explanation_text'):\n",
                "        print(f\"Explanation: {rule_exp['explanation_text']}\")\n",
                "    \n",
                "    return {\n",
                "        'sample_idx': sample_idx,\n",
                "        'true_label': true_label,\n",
                "        'pred_label': pred_label,\n",
                "        'confidence': pred_proba[pred_label],\n",
                "        'rule_explanation': rule_exp\n",
                "    }\n",
                "\n",
                "# Analyze a few samples\n",
                "sample_analyses = []\n",
                "for i in [0, 5, 10, 15, 20]:  # Analyze samples at different indices\n",
                "    if i < len(X_test):\n",
                "        analysis = analyze_sample(i)\n",
                "        sample_analyses.append(analysis)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create summary statistics\n",
                "print(\"\\n=== Summary Statistics ===\")\n",
                "\n",
                "# Model performance summary\n",
                "correct_predictions = sum(1 for a in sample_analyses if a['true_label'] == a['pred_label'])\n",
                "print(f\"Correct predictions: {correct_predictions}/{len(sample_analyses)}\")\n",
                "\n",
                "# Rule-based anomaly scores\n",
                "rule_scores = [a['rule_explanation'].get('anomaly_score', 0) for a in sample_analyses]\n",
                "print(f\"Rule-based anomaly scores: min={min(rule_scores):.3f}, max={max(rule_scores):.3f}, mean={np.mean(rule_scores):.3f}\")\n",
                "\n",
                "# Most common triggered rules\n",
                "all_triggered_rules = []\n",
                "for a in sample_analyses:\n",
                "    all_triggered_rules.extend(a['rule_explanation'].get('triggered_rules', []))\n",
                "\n",
                "if all_triggered_rules:\n",
                "    from collections import Counter\n",
                "    rule_counts = Counter(all_triggered_rules)\n",
                "    print(f\"Most common triggered rules: {rule_counts.most_common(3)}\")\nelse:\n",
                "    print(\"No rules were triggered in the analyzed samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Explainability Insights\n",
                "\n",
                "Let's summarize the insights from our explainability analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n=== Explainability Insights ===\")\n",
                "\n",
                "# Feature importance insights\n",
                "if 'shap_values' in shap_explanation:\n",
                "    shap_values = np.array(shap_explanation['shap_values'])\n",
                "    if shap_values.ndim == 2:\n",
                "        feature_importance = np.mean(np.abs(shap_values), axis=0)\n",
                "        top_features_idx = np.argsort(feature_importance)[-5:][::-1]\n",
                "        \n",
                "        print(\"\\nTop 5 most important features (SHAP):\")\n",
                "        for i, idx in enumerate(top_features_idx):\n",
                "            if idx < len(feature_names):\n",
                "                print(f\"  {i+1}. {feature_names[idx]}: {feature_importance[idx]:.4f}\")\n",
                "\n",
                "# Rule-based insights\n",
                "rule_summary = rule_system.get_rule_summary()\n",
                "print(f\"\\nRule-based system has {rule_summary['total_rules']} rules\")\n",
                "print(f\"Rule types: {rule_summary['rule_types']}\")\n",
                "\n",
                "# Method comparison\n",
                "print(\"\\n=== Method Comparison ===\")\n",
                "print(\"SHAP:\")\n",
                "print(\"  + Provides feature importance with directionality\")\n",
                "print(\"  + Model-agnostic\")\n",
                "print(\"  - Computationally expensive\")\n",
                "print(\"  - Requires background data\")\n",
                "\n",
                "print(\"\\nLIME:\")\n",
                "print(\"  + Local explanations for individual instances\")\n",
                "print(\"  + Model-agnostic\")\n",
                "print(\"  - Can be unstable\")\n",
                "print(\"  - Requires careful parameter tuning\")\n",
                "\n",
                "print(\"\\nRule-based:\")\n",
                "print(\"  + Fast and interpretable\")\n",
                "print(\"  + Domain knowledge integration\")\n",
                "print(\"  + Consistent explanations\")\n",
                "print(\"  - Requires manual rule definition\")\n",
                "print(\"  - May miss complex patterns\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Save Results\n",
                "\n",
                "Let's save our analysis results for future reference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save explanation results\n",
                "results_dir = Path(\"../artifacts/explanations/demo_results\")\n",
                "results_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Save individual explanations\n",
                "import json\n",
                "\n",
                "if 'shap_values' in shap_explanation:\n",
                "    with open(results_dir / \"shap_explanation.json\", 'w') as f:\n",
                "        json.dump(shap_explanation, f, indent=2, default=str)\n",
                "    print(\"âœ… SHAP explanation saved\")\n",
                "\n",
                "if 'explanations' in lime_explanation:\n",
                "    with open(results_dir / \"lime_explanation.json\", 'w') as f:\n",
                "        json.dump(lime_explanation, f, indent=2, default=str)\n",
                "    print(\"âœ… LIME explanation saved\")\n",
                "\n",
                "with open(results_dir / \"rule_explanation.json\", 'w') as f:\n",
                "    json.dump(rule_explanation, f, indent=2, default=str)\n",
                "print(\"âœ… Rule-based explanation saved\")\n",
                "\n",
                "# Save sample analyses\n",
                "with open(results_dir / \"sample_analyses.json\", 'w') as f:\n",
                "    json.dump(sample_analyses, f, indent=2, default=str)\n",
                "print(\"âœ… Sample analyses saved\")\n",
                "\n",
                "# Save model and preprocessor for later use\n",
                "import pickle\n",
                "\n",
                "with open(results_dir / \"demo_model.pkl\", 'wb') as f:\n",
                "    pickle.dump(model, f)\n",
                "print(\"âœ… Model saved\")\n",
                "\n",
                "with open(results_dir / \"preprocessor.pkl\", 'wb') as f:\n",
                "    pickle.dump(preprocessor, f)\n",
                "print(\"âœ… Preprocessor saved\")\n",
                "\n",
                "print(f\"\\nðŸ“ All results saved to {results_dir}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "This demo showcased the comprehensive explainability features of our market anomaly detection system:\n",
                "\n",
                "1. **SHAP explanations** provide global feature importance and local explanations\n",
                "2. **LIME explanations** offer instance-specific interpretations\n",
                "3. **Rule-based explanations** give fast, interpretable insights based on domain knowledge\n",
                "4. **Visualization tools** help understand and compare different explanation methods\n",
                "5. **Unified interface** makes it easy to switch between explanation methods\n",
                "\n",
                "The system provides multiple perspectives on model behavior, helping users understand:\n",
                "- Which features are most important for anomaly detection\n",
                "- Why specific instances were classified as anomalies\n",
                "- How different explanation methods complement each other\n",
                "- Domain-specific insights through rule-based analysis\n",
                "\n",
                "This multi-faceted approach to explainability is crucial for building trust in AI systems used for financial market analysis."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}