{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sequence Preparation Demo\n",
                "\n",
                "This notebook demonstrates the complete feature engineering and sequence preparation pipeline for market data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "import torch\n",
                "from pathlib import Path\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append('../')\n",
                "\n",
                "from src.features.feature_engineering import compute_base_features, normalize_features, select_feature_columns\n",
                "from src.data.sequence_builder import build_sequences, build_targets, MarketSequenceDataset, save_sequences, load_sequences\n",
                "from src.data.dataloader_factory import get_dataloader, create_train_val_test_loaders\n",
                "from src.utils.config_loader import load_config\n",
                "\n",
                "# Set up plotting\n",
                "plt.style.use('default')\n",
                "%matplotlib inline\n",
                "\n",
                "print(\"✅ All imports successful\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Configuration and Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load configuration\n",
                "config = load_config('../configs/config.yaml')\n",
                "print(\"Configuration loaded:\")\n",
                "print(f\"Features config: {config.get('features', {})}\")\n",
                "print(f\"Preprocessing config: {config.get('preprocessing', {})}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load preprocessed data\n",
                "data_path = '../data/processed/sample_preprocessed.csv'\n",
                "df = pd.read_csv(data_path)\n",
                "\n",
                "print(f\"Loaded data shape: {df.shape}\")\n",
                "print(f\"Columns: {list(df.columns)}\")\n",
                "print(f\"\\nFirst few rows:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute base features\n",
                "print(\"Computing base features...\")\n",
                "df_features = compute_base_features(df)\n",
                "\n",
                "print(f\"After feature engineering: {df_features.shape}\")\n",
                "new_columns = [col for col in df_features.columns if col not in df.columns]\n",
                "print(f\"New feature columns: {new_columns}\")\n",
                "\n",
                "# Show sample of new features\n",
                "feature_sample = df_features[['mid_price', 'spread', 'log_return', 'order_imbalance', 'trade_intensity', 'rolling_vol_10']].head()\n",
                "print(\"\\nSample of computed features:\")\n",
                "feature_sample"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normalize features\n",
                "feature_cols_to_normalize = ['mid_price', 'spread', 'order_imbalance', 'trade_intensity', 'rolling_vol_10']\n",
                "print(f\"Normalizing features: {feature_cols_to_normalize}\")\n",
                "\n",
                "df_normalized, scalers = normalize_features(df_features, feature_cols_to_normalize)\n",
                "\n",
                "print(f\"After normalization: {df_normalized.shape}\")\n",
                "print(f\"Scalers created for: {list(scalers.keys())}\")\n",
                "\n",
                "# Show normalization results\n",
                "norm_cols = [f'{col}_z' for col in feature_cols_to_normalize]\n",
                "norm_sample = df_normalized[norm_cols].head()\n",
                "print(\"\\nSample of normalized features:\")\n",
                "norm_sample"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify normalization (mean ≈ 0, std ≈ 1)\n",
                "print(\"Normalization verification:\")\n",
                "for col in norm_cols:\n",
                "    if col in df_normalized.columns:\n",
                "        mean_val = df_normalized[col].mean()\n",
                "        std_val = df_normalized[col].std()\n",
                "        print(f\"{col}: mean={mean_val:.6f}, std={std_val:.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot original vs normalized features\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, col in enumerate(feature_cols_to_normalize):\n",
                "    if i < len(axes):\n",
                "        ax = axes[i]\n",
                "        \n",
                "        # Plot original and normalized\n",
                "        ax.plot(df_normalized[col], label=f'Original {col}', alpha=0.7)\n",
                "        ax.plot(df_normalized[f'{col}_z'], label=f'Normalized {col}', alpha=0.7)\n",
                "        \n",
                "        ax.set_title(f'{col} - Original vs Normalized')\n",
                "        ax.legend()\n",
                "        ax.grid(True, alpha=0.3)\n",
                "\n",
                "# Remove empty subplots\n",
                "for i in range(len(feature_cols_to_normalize), len(axes)):\n",
                "    fig.delaxes(axes[i])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Sequence Building"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select feature columns for sequences\n",
                "feature_cols = [f'{col}_z' for col in feature_cols_to_normalize]\n",
                "print(f\"Feature columns for sequences: {feature_cols}\")\n",
                "\n",
                "# Build sequences\n",
                "seq_len = 50\n",
                "step = 5\n",
                "\n",
                "print(f\"Building sequences with seq_len={seq_len}, step={step}\")\n",
                "sequences = build_sequences(\n",
                "    df_normalized,\n",
                "    seq_len=seq_len,\n",
                "    step=step,\n",
                "    mode='sliding',\n",
                "    feature_cols=feature_cols\n",
                ")\n",
                "\n",
                "print(f\"Sequences shape: {sequences.shape}\")\n",
                "print(f\"Number of sequences: {len(sequences)}\")\n",
                "print(f\"Sequence length: {sequences.shape[1]}\")\n",
                "print(f\"Number of features: {sequences.shape[2]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build targets\n",
                "print(\"Building targets...\")\n",
                "targets = build_targets(\n",
                "    df_normalized,\n",
                "    horizon=1,\n",
                "    target_col='mid_price',\n",
                "    target_type='return'\n",
                ")\n",
                "\n",
                "# Align targets with sequences\n",
                "targets_aligned = targets[:len(sequences)]\n",
                "\n",
                "print(f\"Targets shape: {targets_aligned.shape}\")\n",
                "print(f\"Target statistics:\")\n",
                "print(f\"  Mean: {targets_aligned.mean():.6f}\")\n",
                "print(f\"  Std: {targets_aligned.std():.6f}\")\n",
                "print(f\"  Min: {targets_aligned.min():.6f}\")\n",
                "print(f\"  Max: {targets_aligned.max():.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Save and Load Sequences"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save sequences\n",
                "output_path = '../data/processed/sequences/sample_sequences.npz'\n",
                "metadata = {\n",
                "    'feature_cols': feature_cols,\n",
                "    'seq_len': seq_len,\n",
                "    'step': step,\n",
                "    'n_original_samples': len(df_normalized)\n",
                "}\n",
                "\n",
                "print(f\"Saving sequences to {output_path}\")\n",
                "save_sequences(sequences, targets_aligned, output_path, metadata)\n",
                "\n",
                "# Verify file was created\n",
                "from pathlib import Path\n",
                "if Path(output_path).exists():\n",
                "    file_size = Path(output_path).stat().st_size / 1024  # KB\n",
                "    print(f\"✅ Sequences saved successfully ({file_size:.1f} KB)\")\n",
                "else:\n",
                "    print(\"❌ Failed to save sequences\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load sequences back\n",
                "print(\"Loading sequences from file...\")\n",
                "loaded_sequences, loaded_targets, loaded_metadata = load_sequences(output_path)\n",
                "\n",
                "print(f\"Loaded sequences shape: {loaded_sequences.shape}\")\n",
                "print(f\"Loaded targets shape: {loaded_targets.shape}\")\n",
                "print(f\"Loaded metadata: {loaded_metadata}\")\n",
                "\n",
                "# Verify data integrity\n",
                "assert np.array_equal(sequences, loaded_sequences), \"Sequences don't match!\"\n",
                "assert np.array_equal(targets_aligned, loaded_targets), \"Targets don't match!\"\n",
                "print(\"✅ Data integrity verified\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. PyTorch Dataset and DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create PyTorch dataset\n",
                "dataset = MarketSequenceDataset(loaded_sequences, loaded_targets, loaded_metadata)\n",
                "\n",
                "print(f\"Dataset length: {len(dataset)}\")\n",
                "\n",
                "# Test getting a sample\n",
                "sample_seq, sample_target, sample_metadata = dataset[0]\n",
                "\n",
                "print(f\"Sample sequence shape: {sample_seq.shape}\")\n",
                "print(f\"Sample sequence dtype: {sample_seq.dtype}\")\n",
                "print(f\"Sample target shape: {sample_target.shape}\")\n",
                "print(f\"Sample target dtype: {sample_target.dtype}\")\n",
                "print(f\"Sample metadata: {sample_metadata}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create DataLoader\n",
                "dataloader = get_dataloader(output_path, batch_size=8, shuffle=True)\n",
                "\n",
                "print(f\"DataLoader created with {len(dataloader.dataset)} samples\")\n",
                "print(f\"Number of batches: {len(dataloader)}\")\n",
                "\n",
                "# Get a sample batch\n",
                "for batch_sequences, batch_targets, batch_metadata in dataloader:\n",
                "    print(f\"\\nSample batch:\")\n",
                "    print(f\"  Batch sequences shape: {batch_sequences.shape}\")\n",
                "    print(f\"  Batch targets shape: {batch_targets.shape}\")\n",
                "    print(f\"  Batch metadata keys: {list(batch_metadata.keys())}\")\n",
                "    \n",
                "    # Show some statistics\n",
                "    print(f\"  Sequence value range: [{batch_sequences.min():.4f}, {batch_sequences.max():.4f}]\")\n",
                "    print(f\"  Target value range: [{batch_targets.min():.4f}, {batch_targets.max():.4f}]\")\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Train/Val/Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create train/val/test DataLoaders\n",
                "train_loader, val_loader, test_loader = create_train_val_test_loaders(\n",
                "    loaded_sequences,\n",
                "    loaded_targets,\n",
                "    batch_size=16,\n",
                "    train_frac=0.7,\n",
                "    val_frac=0.2,\n",
                "    save_dir='../data/processed/sequences'\n",
                ")\n",
                "\n",
                "print(f\"Train loader: {len(train_loader.dataset)} samples, {len(train_loader)} batches\")\n",
                "print(f\"Val loader: {len(val_loader.dataset)} samples, {len(val_loader)} batches\")\n",
                "print(f\"Test loader: {len(test_loader.dataset)} samples, {len(test_loader)} batches\")\n",
                "\n",
                "# Test each loader\n",
                "for name, loader in [('Train', train_loader), ('Val', val_loader), ('Test', test_loader)]:\n",
                "    for batch_seq, batch_targets, batch_metadata in loader:\n",
                "        print(f\"{name} batch shape: {batch_seq.shape}\")\n",
                "        break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Sequence Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize a sample sequence\n",
                "sample_idx = 0\n",
                "sample_sequence = loaded_sequences[sample_idx]  # Shape: (seq_len, n_features)\n",
                "sample_target = loaded_targets[sample_idx]\n",
                "\n",
                "print(f\"Visualizing sequence {sample_idx}\")\n",
                "print(f\"Sequence shape: {sample_sequence.shape}\")\n",
                "print(f\"Target value: {sample_target:.6f}\")\n",
                "\n",
                "# Create interactive plot with Plotly\n",
                "fig = make_subplots(\n",
                "    rows=len(feature_cols), cols=1,\n",
                "    subplot_titles=feature_cols,\n",
                "    shared_xaxes=True,\n",
                "    vertical_spacing=0.02\n",
                ")\n",
                "\n",
                "for i, feature_name in enumerate(feature_cols):\n",
                "    fig.add_trace(\n",
                "        go.Scatter(\n",
                "            x=list(range(seq_len)),\n",
                "            y=sample_sequence[:, i],\n",
                "            mode='lines+markers',\n",
                "            name=feature_name,\n",
                "            line=dict(width=2),\n",
                "            marker=dict(size=4)\n",
                "        ),\n",
                "        row=i+1, col=1\n",
                "    )\n",
                "\n",
                "fig.update_layout(\n",
                "    height=200 * len(feature_cols),\n",
                "    title=f'Sample Sequence {sample_idx} (Target: {sample_target:.6f})',\n",
                "    showlegend=False\n",
                ")\n",
                "\n",
                "fig.update_xaxes(title_text=\"Time Step\", row=len(feature_cols), col=1)\n",
                "\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot multiple sequences for comparison\n",
                "n_sequences_to_plot = 3\n",
                "feature_to_plot = 0  # Index of feature to plot (mid_price_z)\n",
                "\n",
                "fig = go.Figure()\n",
                "\n",
                "for i in range(min(n_sequences_to_plot, len(loaded_sequences))):\n",
                "    fig.add_trace(\n",
                "        go.Scatter(\n",
                "            x=list(range(seq_len)),\n",
                "            y=loaded_sequences[i][:, feature_to_plot],\n",
                "            mode='lines',\n",
                "            name=f'Sequence {i} (target: {loaded_targets[i]:.4f})',\n",
                "            line=dict(width=2)\n",
                "        )\n",
                "    )\n",
                "\n",
                "fig.update_layout(\n",
                "    title=f'Multiple Sequences - {feature_cols[feature_to_plot]}',\n",
                "    xaxis_title='Time Step',\n",
                "    yaxis_title='Normalized Value',\n",
                "    hovermode='x unified'\n",
                ")\n",
                "\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Summary and Next Steps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=== SEQUENCE PREPARATION PIPELINE SUMMARY ===\")\n",
                "print(f\"✅ Original data: {df.shape[0]} samples, {df.shape[1]} columns\")\n",
                "print(f\"✅ Feature engineering: Added {len(new_columns)} new features\")\n",
                "print(f\"✅ Normalization: {len(feature_cols)} features normalized\")\n",
                "print(f\"✅ Sequences: {len(loaded_sequences)} sequences of length {seq_len}\")\n",
                "print(f\"✅ Features per sequence: {len(feature_cols)}\")\n",
                "print(f\"✅ Targets: {len(loaded_targets)} return predictions\")\n",
                "print(f\"✅ Data splits: Train({len(train_loader.dataset)}), Val({len(val_loader.dataset)}), Test({len(test_loader.dataset)})\")\n",
                "print(f\"✅ Saved to: {output_path}\")\n",
                "\n",
                "print(\"\\n=== READY FOR RL AGENT TRAINING ===\")\n",
                "print(\"The sequences are now ready to be used for:\")\n",
                "print(\"• Reinforcement Learning agent training\")\n",
                "print(\"• Supervised learning models\")\n",
                "print(\"• Time series forecasting\")\n",
                "print(\"• Anomaly detection\")\n",
                "\n",
                "print(\"\\n=== NEXT STEPS ===\")\n",
                "print(\"1. Implement RL agent architecture\")\n",
                "print(\"2. Define reward functions\")\n",
                "print(\"3. Set up training loop\")\n",
                "print(\"4. Integrate with rule-based systems\")\n",
                "print(\"5. Add explainability components\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}